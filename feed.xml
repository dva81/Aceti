<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://dva81.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://dva81.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-12-16T14:19:36+00:00</updated><id>https://dva81.github.io/feed.xml</id><title type="html">blank</title><subtitle></subtitle><entry><title type="html">AI as a means to work faster</title><link href="https://dva81.github.io/blog/2024/AI-as-a-means-to-work-faster/" rel="alternate" type="text/html" title="AI as a means to work faster"/><published>2024-09-20T00:00:00+00:00</published><updated>2024-09-20T00:00:00+00:00</updated><id>https://dva81.github.io/blog/2024/AI%20as%20a%20means%20to%20work%20faster</id><content type="html" xml:base="https://dva81.github.io/blog/2024/AI-as-a-means-to-work-faster/"><![CDATA[<h1 id="context">Context</h1> <p>I had a meeting and one of the topics was ‚Äúthe bench‚Äù. I had some thoughts on the matter and wanted to write a motivation that can help our organization.</p> <p>I also wanted to see how fast I could make a minimal viable paper üòâ with the help of generative AI and gave myself 30 minutes.</p> <h1 id="lets-get-started">Let‚Äôs get started</h1> <p>I wrote some key thoughts and gave them to ChatGPT https://openai.com/chatgpt/overview/</p> <h2 id="first-the-initiatives">First the initiatives</h2> <ul> <li>The bench is not a punishment but an opportunity to grow, expand and train!</li> <li>Content creation</li> <li>Write use cases</li> <li>Blog post and white papers Process improvement</li> <li>Improve the estimation process</li> <li>AI in development Certification</li> <li>Get Certified Training Soft skill training ‚Äì communication Mastery of skill</li> </ul> <h2 id="then-action-plan">Then Action Plan</h2> <ul> <li>Treat every initiative as a project and not individuals responsibility</li> <li>Administration - Dedicated project codes give insights in effort and result</li> <li>Connect initiatives to personal goals</li> <li>follow up is key ‚Äì people need guidance and leadership .There is no such thing as self-managing teams</li> </ul> <h2 id="the-result">The result</h2> <p>The draft document of this 30 minutes experiment is next.</p> <blockquote> <p>Not so bad at all‚Ä¶. Happy reading.</p> </blockquote> <h1 id="the-bench-as-an-opportunity-for-growth">The Bench as an opportunity for growth</h1> <p>The concept of ‚Äúthe bench‚Äù is often seen in a negative light. However, in our organization, the bench is not a punishment but a valuable opportunity for our teams to grow, expand their skillsets, and train for the future. I would like to highlight several initiatives that can help us leverage this time productively, aligning with our long-term strategic goals.</p> <h2 id="content-creation">Content Creation</h2> <p>Bench time provides our team members with a unique opportunity to contribute to knowledge sharing and brand building through content creation, which helps position us as industry leaders.</p> <p>Write Use Cases: Team members can document recent project experiences, challenges, and solutions that can serve as best practices for the organization and as valuable resources for future projects.</p> <p>Blog Posts and White Papers: Encouraging employees to create blog posts or white papers on relevant industry topics will not only enhance their writing and communication skills but also elevate our company‚Äôs thought leadership and digital presence.</p> <h1 id="process-improvement">Process Improvement</h1> <p>Leveraging bench time to refine internal processes is another key area for focus. This can drive efficiency and innovation in our core operations.</p> <p>Improve the Estimation Process: Employees can analyze historical data, identify trends, and develop improved project estimation frameworks that ensure more accurate forecasts for timelines, costs, and resources in future projects.</p> <p>AI in Development: Investigating how AI tools can support and enhance our development processes is another area ripe for exploration. Team members can explore automation, machine learning models, or AI-driven testing processes that will improve efficiency.</p> <h2 id="certification">Certification</h2> <p>Professional certifications not only advance an individual‚Äôs career but also enhance the company‚Äôs capabilities. Allocating time for employees on the bench to pursue certifications in relevant technologies or methodologies will equip our teams with cutting-edge knowledge.</p> <p>Get Certified: Employees can pursue industry-recognized certifications (e.g., AWS, PMP, Agile, etc.) that align with their expertise and the company‚Äôs strategic objectives.</p> <h2 id="training--development">Training &amp; Development</h2> <p>The bench provides an ideal moment for focused professional development through both hard and soft skills training.</p> <p>Soft Skill Training ‚Äì Communication: Communication is critical to the success of every project. Offering communication workshops will improve team members‚Äô ability to collaborate effectively, articulate their ideas clearly, and engage with clients more professionally.</p> <p>Mastery of Skills: Encourage employees to take time for deep dives into their technical specialties or explore new areas, ensuring they return to client projects with mastery in relevant technologies or methodologies.</p> <h1 id="action-plan-maximizing-the-bench-as-a-growth-opportunity">Action Plan: Maximizing the Bench as a Growth Opportunity</h1> <h2 id="objective">Objective</h2> <p>Transform bench time into a structured, high-value growth opportunity by treating initiatives as formal projects, connecting them to personal goals, and ensuring accountability through leadership and oversight.</p> <h2 id="treat-every-initiative-as-a-project-not-an-individual-responsibility">Treat Every Initiative as a Project, Not an Individual Responsibility</h2> <ul> <li> <p>Action Item: Formalize each initiative (content creation, process improvement, certification, training) as a project with clear deliverables, timelines, and objectives.</p> </li> <li> <p>Steps:</p> <ul> <li> <p>Assign a project manager or lead to oversee each initiative, ensuring progress is tracked and goals are met.</p> </li> <li> <p>Establish a project charter for each initiative to clearly define scope, objectives, stakeholders, and outcomes.</p> </li> <li> <p>Ensure team members are aware that these initiatives are formalized projects, not just individual tasks or side assignments.</p> </li> </ul> </li> <li> <p>Success Metric: All initiatives are tracked in a project management system, with clear ownership and regular updates.</p> </li> </ul> <h2 id="administration-dedicated-project-codes-to-track-effort-and-results">Administration: Dedicated Project Codes to Track Effort and Results</h2> <ul> <li> <p>Action Item: Assign dedicated project codes to all bench-related initiatives to track the time and effort spent on each.</p> </li> <li> <p>Steps:</p> <ul> <li> <p>Work with the administration team to set up unique project codes for each bench initiative.</p> </li> <li> <p>Ensure that all team members log their hours and progress against these codes in the project management or time-tracking system.</p> </li> <li> <p>Use the data from these codes to review effort, productivity, and overall outcomes, allowing for better resource allocation in future bench periods.</p> </li> </ul> </li> <li> <p>Success Metric: 100% tracking of time spent on initiatives through project codes, leading to data-driven insights into the effectiveness of bench activities.</p> </li> </ul> <h2 id="connect-initiatives-to-personal-goals">Connect Initiatives to Personal Goals</h2> <ul> <li> <p>Action Item: Align each initiative with the individual‚Äôs personal growth and development goals, ensuring the initiative adds value both to the organization and the employee.</p> </li> <li> <p>Steps:</p> <ul> <li> <p>Conduct one-on-one meetings between managers and team members to discuss personal goals and identify which bench initiatives align with their professional development.</p> </li> <li> <p>Assign individuals to initiatives that help them build skills or gain experience relevant to their career path.</p> </li> <li> <p>Create individualized learning or achievement goals that are linked to the initiatives they are assigned to.</p> </li> </ul> </li> <li> <p>Success Metric: Each team member has a development plan that connects at least one bench initiative to their personal career goals.</p> </li> </ul> <h2 id="follow-up-is-key-leadership-and-guidance-are-crucial">Follow-up Is Key: Leadership and Guidance are Crucial</h2> <ul> <li> <p>Action Item: Establish regular follow-ups and check-ins with team members to provide leadership, support, and direction. Ensure that teams are guided and not left to self-manage.</p> </li> <li> <p>Steps:</p> <ul> <li> <p>Schedule bi-weekly or weekly status meetings with initiative leads and team members to review progress, address challenges, and offer guidance.</p> </li> <li> <p>Ensure project managers or team leads are providing clear guidance and setting expectations at each stage of the initiative.</p> </li> <li> <p>Hold leadership accountable for providing regular feedback, mentoring, and removing obstacles that hinder progress.</p> </li> </ul> </li> <li> <p>Success Metric: Consistent follow-up and guidance result in project milestones being met on time, with minimal issues or delays due to lack of leadership.</p> </li> </ul> <h2 id="no-self-managing-teams-provide-structured-oversight">No Self-Managing Teams: Provide Structured Oversight</h2> <ul> <li> <p>Action Item: While encouraging ownership, ensure all teams have clear oversight and leadership to maintain direction and accountability.</p> </li> <li> <p>Steps:</p> <ul> <li> <p>Assign a senior leader or project sponsor to each initiative to provide higher-level oversight and ensure alignment with organizational goals.</p> </li> <li> <p>Establish a reporting structure where team leads report on progress, risks, and issues to their sponsors on a regular basis.</p> </li> <li> <p>Implement review checkpoints where senior leadership can assess the impact of initiatives and make adjustments if needed.</p> </li> </ul> </li> <li> <p>Success Metric: All initiatives report progress to leadership on a structured basis, ensuring no initiative is neglected or lacks direction.</p> </li> </ul> <h1 id="conclusion">Conclusion</h1> <p>By treating the bench as a structured opportunity for growth rather than downtime, we can foster a culture of continuous improvement and innovation within our teams. This approach will ensure that our employees remain sharp, motivated, and ready to deliver high-value solutions when they return to active projects. It will also reinforce our reputation as a learning organization that invests in the development of its people.</p> <p>By formalizing bench initiatives as structured projects, assigning appropriate leadership, and connecting them to personal goals, we can ensure that bench time is productive, aligned with both individual and organizational growth, and contributes to long-term success.</p> <hr/> <p>My focus is on structuring, automating and managing business processes using Agile and DevOps best practices. This creates working environments where business continuity, transparency and human capital come first. Reach out to me on <a href="https://www.linkedin.com/in/dennisvanaelst">LinkedIn</a> or check out my <a href="https://github.com/dva81">github</a> or <a href="https://www.dennisvanaelst.net/">blog</a> for more tips and tricks.</p> <hr/> <p>The ideas and underlying essence are original and generated by a human author. The organization, grammar, and presentation may have been enhanced by the use of AI.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[I had a meeting and one of the topics was ‚Äúthe bench‚Äù. I had some thoughts on the matter and wanted to write a motivation that can help our organization. I also wanted to see how fast I could make a minimal viable paper üòâ with the help of generative AI and gave myself 30 minutes.]]></summary></entry><entry><title type="html">An advanced pipeline in Azure DevOps and GITHUB for Power Platform Solutions</title><link href="https://dva81.github.io/blog/2024/advanced-pipeline-AzureDevOps/" rel="alternate" type="text/html" title="An advanced pipeline in Azure DevOps and GITHUB for Power Platform Solutions"/><published>2024-07-19T00:00:00+00:00</published><updated>2024-07-19T00:00:00+00:00</updated><id>https://dva81.github.io/blog/2024/advanced-pipeline-AzureDevOps</id><content type="html" xml:base="https://dva81.github.io/blog/2024/advanced-pipeline-AzureDevOps/"><![CDATA[<p>When working with many developers or designers in highly secure environment with a lot of compliance rules and regulations, Power Platform can be challenging to maintain. In this <a href="https://www.linkedin.com/pulse/azure-devops-easily-deploy-power-platform-solution-dennis-van-aelst-mzfpe/?trackingId=Zt9plSeCTg2OyehjOFpuog%3D%3D">Azure DevOps: Easily deploy a Power platform solution - LinkedIn</a> article, I gave an example on how to create a simple DevOps pipeline.</p> <p>This time I will show you two advanced pipelines to export and import a Power Platform solution with a GITHUB connection. The thought behind this is that the highly regulated enterprises have more complex working environments and deployment needs.</p> <ul> <li>Many developers are working on the same solution in different development environments.</li> <li>Code or configuration check must be done before deploying preferably automated</li> <li>Branching and merging policies.</li> <li>Standard configurations must be added automatically after development</li> </ul> <h1 id="setting-the-stage">Setting the stage</h1> <p>We will be using the following components.</p> <ul> <li>Azure DevOps environment for the build and release pipelines</li> <li>GITHUB repository for storing the configuration and merging the different brances</li> <li>Power Platform environment with a solution to export</li> </ul> <p>The example will be importing from only one environment but it can be extended if needed. If you are reading this article, I can safely assume you know your way around Microsoft Power Platform. However source control is not always related to low code so if you are new to GITHUB check out this Beginner‚Äôs guide to GitHub repositories: <a href="https://github.blog/2024-06-24-beginners-guide-to-github-repositories-how-to-create-your-first-repo/">How to create your first repo - The GitHub Blog</a></p> <h1 id="build">Build</h1> <p>There are two pipelines. Get the Solution and Pack and drop.</p> <p><img src="https://github.com/user-attachments/assets/5dd9d6ee-4239-458a-a15f-5a0e658ed683" alt="Build"/></p> <h2 id="get-the-solution">Get the Solution</h2> <p>The goal is to export the solution from the Power Platform environment and store the configuration in GITHUB under a new branch. This way all the components are available in source control and can be handled in code as well. This makes batch updates and checks easier, creating a new version ready to be released via the pack and drop pipeline.</p> <p><img src="https://github.com/user-attachments/assets/1ca58311-b0c7-4854-a3b3-99b42f81540f" alt="Get the Solution"/></p> <p>The first three tasks are simple. Before they start, the Checkout ‚Äì job creates / clones the Github repo on the agents file system. This way we can use that location to clean the repository before unpacking the solution in that location.</p> <p><img src="https://github.com/user-attachments/assets/48762fd5-985f-4876-a374-871ae7cd5893" alt="Checkout"/></p> <p>In the Clean repo step, The GIT rm command is used to remove the old configuration making it ready to accept the new incoming.</p> <p><img src="https://github.com/user-attachments/assets/801024a4-f39b-4178-bbdc-bca224ed6750" alt="Clean"/></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>write-host "Set location"
Set-Location -Path $(Build.Repository.LocalPath)

write-host "Start GIT Stuff"
git config user.email "$(Build.RequestedForEmail)"
git config user.name $(Build.RequestedForId)

write-host "Switch"
git switch -c $(Build.BuildId)
</code></pre></div></div> <p>After unpacking, we can send the files to GITHUB in a new branch. I am using predefined variables <a href="https://learn.microsoft.com/en-us/azure/devops/pipelines/build/variables?view=azure-devops&amp;tabs=yaml#identity_values">Predefined variables - Azure Pipelines Microsoft Learn</a> because I like standard basic things.</p> <p><img src="https://github.com/user-attachments/assets/18453d97-84e8-4584-9471-6ad541149368" alt="unpacking"/></p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>write-host "Set location"
Set-Location -Path $(Build.Repository.LocalPath)

write-host "Start GIT Stuff"
git config user.email "$(Build.RequestedForEmail)"
git config user.name $(Build.RequestedForId)

write-host "Switch"
git switch -c $(Build.BuildId)
# git checkout -b $(Build.BuildId)

write-host "Adding"
git status
git add *

write-host "Commit"
git commit -m "$(Build.SourceVersionMessage)"
git status

write-host "Push code to new repo"
git -c http.extraheader="AUTHORIZATION: bearer $(System.AccessToken)" push origin $(Build.BuildId)
git status
</code></pre></div></div> <h2 id="things-did-not-go-as-planned">Things did not go as planned</h2> <p>Some things took more time than others. These types configuration of things are an intricate maze of tools, tasks and settings.</p> <p><strong>The Git push did not work</strong></p> <p>The Git push did not work and I got a message the ‚Äúauthentication was not done properly‚Äù. I missed a setting in the Agent Job. <a href="https://stackoverflow.com/questions/64803872/azure-pipeline-cannot-prompt-because-terminal-prompts-have-been-disabled">git - Azure Pipeline, Cannot prompt because terminal prompts have been disabled - Stack Overflow</a></p> <p><img src="https://github.com/user-attachments/assets/35fb26fc-d67a-4037-aab1-64c95ce31b3f" alt="push"/></p> <p><strong>Error Not a repo</strong></p> <p>This was because I cleaned the repo before filling it again. I solved this with the GIT rm command. Which did not destroy the cloned repo. <a href="https://komodor.com/blog/solving-fatal-not-a-git-repository-error/">Solved: fatal: Not a git repository (or any of the parent directories): .git (komodor.com)</a></p> <p><strong>Unpack vs unzip does not make a difference.</strong></p> <p>What is strange is that the [Content_types].xml is not extracted in both cases and files in the root are placed in the folder ‚Äòother‚Äô. I lost some figering this out. However after packing the Solution, it does create the correct structure again‚Ä¶</p> <p><img src="https://github.com/user-attachments/assets/36170d33-3513-4a48-965a-6a25f9335d15" alt="Unpack"/></p> <p><img src="https://github.com/user-attachments/assets/9ff41786-dcf3-49e2-809f-e3929c48a452" alt="Unpack"/></p> <p><img src="https://github.com/user-attachments/assets/0f476b28-d247-44d9-babf-87d688717027" alt="Unpack"/></p> <h1 id="pack-and-drop">Pack and drop</h1> <p>This pipeline gets the configuration items from the GITHUB repo and packs the Solution again to a managed solution. out of the box you cannot pack from unmanaged to managed and visa versa. The result is a deployable artifact that can be released to any environment. I did not show the deployment settings in the example. Check out my other article for that. You will need to incorporate all connections references and other dependancies like custom connectors.</p> <p><img src="https://github.com/user-attachments/assets/e500ec17-0284-4b47-8b32-3191725d0e80" alt="Pack and drop"/></p> <h1 id="release-pipelines">Release pipelines</h1> <p>The release pipeline is easy. We are working with managed solutions. Unmanaged is not advised! Microsoft considers these as still under development, and you can import or export as unmanaged. You can modify unmanaged solutions. Managed solutions are complete solutions ready for distribution that you cannot modify after importing them to the selected environment. These solutions are intended for production environments. More info on: <a href="https://learn.microsoft.com/en-us/power-apps/maker/data-platform/solution-layers">Solution layers - Power Apps | Microsoft Learn</a></p> <p><img src="https://github.com/user-attachments/assets/2b2f9846-aa55-40f3-9ad2-734128707a09" alt="pipelines"/></p> <p>By using the managed solution all your environments stay nice and clean.</p> <p>Here is an example of a multi stage environment. You can even make this dynamic if you incorporate pipelines and scripts for environment provisioning and use the API for Azure DevOps to automatically create pipelines and release configurations.</p> <p><img src="https://github.com/user-attachments/assets/0f0f5ffb-4e73-4699-88bd-7f27542f00d6" alt="release"/></p> <h1 id="a-parting-note">A parting note</h1> <p>This way method provides a way to introduce all capabilities of modern version control on all aspects of a Power Platform solution. Beware though. You are merging configurations, not real code. The syntax may be ok but that does not mean it will work! The Power Platform is not really intended to use this way. So be carefull!</p> <p>My focus is on structuring, automating and managing business processes using Agile and DevOps best practices. This creates working environments where business continuity, transparency and human capital come first. Reach out to me on <a href="https://www.linkedin.com/in/dennisvanaelst">LinkedIn</a> or check out my <a href="https://github.com/dva81">github</a> or <a href="https://www.dennisvanaelst.net/">blog</a> for more tips and tricks.</p> <hr/> <p>The ideas and underlying essence are original and generated by a human author. The organization, grammar, and presentation may have been enhanced by the use of AI.</p>]]></content><author><name></name></author><category term="PowerPlatform"/><category term="AI"/><category term="DevOps"/><category term="Copilot"/><summary type="html"><![CDATA[This time I will show you two advanced pipeline to export and import a Power Platform solution with a GITHUB connection. The thought behind this is that the highly regulated enterprises have more complex working environments and deployment needs.]]></summary></entry><entry><title type="html">Skills vs Connectors in Microsoft Copilot Studio - Making the Right Choice</title><link href="https://dva81.github.io/blog/2024/Skills-vs-Connectors/" rel="alternate" type="text/html" title="Skills vs Connectors in Microsoft Copilot Studio - Making the Right Choice"/><published>2024-07-07T00:00:00+00:00</published><updated>2024-07-07T00:00:00+00:00</updated><id>https://dva81.github.io/blog/2024/Skills-vs-Connectors</id><content type="html" xml:base="https://dva81.github.io/blog/2024/Skills-vs-Connectors/"><![CDATA[<p>In the evolving landscape of automation and AI integration, Microsoft Copilot Studio offers two primary methods for enhancing functionality: Skills and Connectors. Understanding the differences, strengths, and best use cases for each can help organizations make informed decisions. This post explores the key aspects of Skills and Connectors, and provides guidance on selecting the right approach for your projects.</p> <h1 id="understanding-connectors">Understanding Connectors</h1> <p>Connectors in the Power Platform provide a low-code solution to integrate various services and applications. This approach is particularly useful for users who want to extend API calls without delving into extensive coding. Here are some key points about Connectors:</p> <ul> <li><strong>Preview Availability</strong>: Connectors are currently available in preview within the Power Platform.</li> <li><strong>Low-Code Approach</strong>: Designed for ease of use, enabling users to integrate services with minimal coding.</li> <li><strong>DLP Policy Impact</strong>: Data Loss Prevention policies apply, with standard limitations allowing 500 calls per minute per connector. These limits are adjustable based on the environment.</li> <li><strong>Authentication</strong>: Proper authentication needs to be verified to ensure secure connections.</li> </ul> <h1 id="exploring-skills">Exploring Skills</h1> <p>Skills offer a more flexible, pro-code approach, requiring Azure infrastructure. This method is ideal for users with coding expertise who need to implement complex customizations. Key features of Skills include:</p> <ul> <li><strong>Pro-Code Flexibility</strong>: Greater flexibility due to the ability to write and modify code.</li> <li><strong>Azure Infrastructure</strong>: Requires setup and management of Azure resources.</li> <li><strong>Extended Capabilities</strong>: Skills can extend further than connectors, especially when paired with Copilot extensions.</li> </ul> <h1 id="user-experience-in-copilot">User Experience in Copilot</h1> <p>Regardless of whether you choose Skills or Connectors, the user experience within Copilot remains largely consistent. Both methods aim to streamline the integration process and enhance functionality.</p> <h1 id="making-the-decision">Making the Decision</h1> <p>For Proof of Concept (POC) use cases, the primary strategy is to use custom connectors. This approach allows for quick integration and testing without extensive coding. However, it‚Äôs crucial to continuously evaluate the technical and functional requirements of your project. If the need for more advanced customization arises, considering Skills might be necessary.</p> <h1 id="action-plan">Action Plan</h1> <p>To effectively implement Connectors or Skills, consider the following steps:</p> <ol> <li><strong>Performance Overview</strong>: Assess performance needs and peak usage to estimate the number of API calls required.</li> <li><strong>Limit Adjustments</strong>: Adjust limits as necessary and manage these changes from an Application Lifecycle Management (ALM) perspective.</li> <li><strong>Performance Testing</strong>: Conduct thorough performance testing to ensure the chosen method meets your requirements.</li> </ol> <p>By carefully evaluating your project‚Äôs needs and understanding the capabilities of both Skills and Connectors, you can make informed decisions that align with your goals and resources.</p> <hr/> <p>For more detailed information on using Microsoft Bot Framework skills and Power Platform connectors, refer to the official <a href="https://learn.microsoft.com/">Microsoft Copilot Studio documentation</a>.</p> <hr/> <p>My focus is on structuring, automating and managing business processes using Agile and DevOps best practices. This creates working environments where business continuity, transparency and human capital come first. Reach out to me on <a href="https://www.linkedin.com/in/dennisvanaelst">LinkedIn</a> or check out my <a href="https://github.com/dva81">github</a> or <a href="https://www.dennisvanaelst.net/">blog</a> for more tips and tricks.</p> <hr/> <p>The ideas and underlying essence are original and generated by a human author. The organization, grammar, and presentation may have been enhanced by the use of AI.</p>]]></content><author><name></name></author><category term="PowerPlatform"/><category term="AI"/><category term="DevOps"/><category term="Copilot"/><summary type="html"><![CDATA[This article provides a foundational understanding to help you navigate the choice between Skills and Connectors in Microsoft Copilot Studio.]]></summary></entry><entry><title type="html">Streamline Your Time Tracking - How to Use Outlook and Power Automate for Efficient Reporting</title><link href="https://dva81.github.io/blog/2024/Streamline-Your-Time-Tracking/" rel="alternate" type="text/html" title="Streamline Your Time Tracking - How to Use Outlook and Power Automate for Efficient Reporting"/><published>2024-06-30T00:00:00+00:00</published><updated>2024-06-30T00:00:00+00:00</updated><id>https://dva81.github.io/blog/2024/Streamline-Your-Time-Tracking</id><content type="html" xml:base="https://dva81.github.io/blog/2024/Streamline-Your-Time-Tracking/"><![CDATA[<p>If you are an organized consultant or developer, you might recognize the screenshot from the Outlook calendar below. It‚Äôs color-coded, organized, and includes different topics, meetings, customers, and projects. When working with various customers and projects, you often need to fill in timesheets for each one in multiple systems and formats. I constantly lose track and am not good at handling multi-faceted administration across different tools and software. To simplify this, I devised a straightforward method to log all my activities in Outlook and generate simple weekly reports.</p> <p>Check out my post on LinkedIn <a href="https://www.linkedin.com/pulse/streamline-your-time-tracking-how-use-outlook-power-dennis-van-aelst-4u4ne/?trackingId=Gf8WIHj%2FQG27H8lGUZN38g%3D%3D">Streamline Your Time Tracking: How to Use Outlook and Power Automate for Efficient Reporting</a>) .</p> <hr/> <p>My focus is on structuring, automating and managing business processes using Agile and DevOps best practices. This creates working environments where business continuity, transparency and human capital come first. Reach out to me on <a href="https://www.linkedin.com/in/dennisvanaelst">LinkedIn</a> or check out my <a href="https://github.com/dva81">github</a> or <a href="https://www.dennisvanaelst.net/">blog</a> for more tips and tricks.</p> <hr/> <p>The ideas and underlying essence are original and generated by a human author. The organization, grammar, and presentation may have been enhanced by the use of AI.</p>]]></content><author><name></name></author><category term="PowerPlatform"/><category term="AI"/><summary type="html"><![CDATA[When working with various customers and projects, you often need to fill in timesheets for each one in multiple systems and formats. I devised a straightforward method to log all my activities in Outlook and generate simple weekly reports.]]></summary></entry><entry><title type="html">Azure DevOps - Easily deploy a Power platform solution</title><link href="https://dva81.github.io/blog/2024/deploy-Power-platform-solutions/" rel="alternate" type="text/html" title="Azure DevOps - Easily deploy a Power platform solution"/><published>2024-06-07T00:00:00+00:00</published><updated>2024-06-07T00:00:00+00:00</updated><id>https://dva81.github.io/blog/2024/deploy-Power-platform-solutions</id><content type="html" xml:base="https://dva81.github.io/blog/2024/deploy-Power-platform-solutions/"><![CDATA[<p>I have been an Azure DevOps enthusiast for years. The ease of use and flexibility of the platform are super. In this article I am sharing my not-so-complex take on deploying a Power Platform Solution across environments. I will explain how to use a repo, build pipeline and release to different environments.</p> <h1 id="repos">Repos</h1> <p>There is no need to download the solution in a repo if you are not going to manipulate the source / zip file. Using the repo for the deployment settings json file is a good practice as these are configurations that are not managed in the solution. This way you can have version control over the deployment settings. The solution versions are managed in Power Platform or you can roll back from the artifact.</p> <p><img src="https://github.com/dva81/dva81.github.io/assets/65031840/9ed4499a-b617-44de-9df4-0c93aeb1bd00" alt="image"/></p> <h1 id="pipelines----build-artifact">Pipelines - build artifact</h1> <p>I see pipelines as a means to create a deployable artifact of deployable item. So for me it can be limited to the steps to collect and package the components that need to be deployed. You can either schedule this or start this manually if you are ready to deploy.</p> <p><img src="https://github.com/dva81/dva81.github.io/assets/65031840/674d2575-bf4e-4d2b-8230-dc44428dd29c" alt="pipeline actions"/></p> <p><img src="https://github.com/dva81/dva81.github.io/assets/65031840/8502521d-d641-4a56-b9ea-ff25f860f638" alt="artifact content"/></p> <p>This package contains everything you need to deploy to any environment. So even if you want to roll back the development environment you can do it with this package.</p> <h1 id="pipelines----release">Pipelines - Release</h1> <p>The release stages are set up from the build output / artifact. Everything is in the artifact, there is no need for other sources. In this example we have three environments to deploy. This can be across tenants if needed. We use the service connections for the connections.</p> <p><img src="https://github.com/dva81/dva81.github.io/assets/65031840/96a44216-f9fd-4ec3-8ab2-7828c6861566" alt="release stages"/></p> <p>As far as actions go. Always install the tool on the agent and import the solution using the deployment settings json file we configured in the repo.</p> <p><img src="https://github.com/dva81/dva81.github.io/assets/65031840/9ef2c0b1-f4e7-4589-bc81-546229476b69" alt="stage actions"/></p> <p><img src="https://github.com/dva81/dva81.github.io/assets/65031840/0f5fb92b-1154-436f-8821-8336a7ca3347" alt="deployment settings"/></p> <h1 id="thats-it-no-need-to-overcomplicate">That‚Äôs it. No need to overcomplicate.</h1> <p>Hope this helps! Feel free to reach out on LinkedIn.</p> <p>Also check out this post if you are interested in Azure DevOps! <a href="https://www.dennisvanaelst.net/blog/2023/Docs-as-Code/">Boosting Efficiency Docs-as-Code Strategies with Power Platform and Azure DevOps</a> or this https://learn.microsoft.com/en-us/shows/devops-lab/how-to-deploy-power-platform-with-azure-devops</p> <p>My focus is on structuring, automating and managing business processes using Agile and DevOps best practices. This creates working environments where business continuity, transparency and human capital come first. Reach out to me on <a href="https://www.linkedin.com/in/dennisvanaelst">LinkedIn</a> or check out my <a href="https://github.com/dva81">github</a> or <a href="https://www.dennisvanaelst.net/">blog</a> for more tips and tricks.</p> <hr/> <p>The ideas and underlying essence are original and generated by a human author. The organization, grammar, and presentation may have been enhanced by the use of AI.</p>]]></content><author><name></name></author><category term="PowerPlatform"/><category term="AI"/><category term="DevOps"/><summary type="html"><![CDATA[In this article I am sharing my take on deploying a Power Platform Solution across environments. How to use a repo, build pipeline(s) and release to different environments.]]></summary></entry><entry><title type="html">Document Processing with AI Builder - A Practical Guide to the document automation toolkit</title><link href="https://dva81.github.io/blog/2024/AI-builder-quick-guide/" rel="alternate" type="text/html" title="Document Processing with AI Builder - A Practical Guide to the document automation toolkit"/><published>2024-06-05T00:00:00+00:00</published><updated>2024-06-05T00:00:00+00:00</updated><id>https://dva81.github.io/blog/2024/AI-builder%20quick%20guide</id><content type="html" xml:base="https://dva81.github.io/blog/2024/AI-builder-quick-guide/"><![CDATA[<p>In today‚Äôs fast-paced digital landscape, document automation is an essential tool for businesses looking to improve efficiency and accuracy. Microsoft‚Äôs AI Builder provides a comprehensive solution for automating document processing, integrating seamlessly with other Microsoft services like SharePoint and Teams. This blog post delves into the workings of the Document Automation Toolkit within AI Builder, detailing the steps involved in setting it up and the adjustments necessary to tailor it to specific needs.</p> <h1 id="getting-started-out-of-the-box-functionality">Getting Started: Out-of-the-Box Functionality</h1> <p>You can access the document automation toolkit in Power Automate. Learn about the toolkit on <a href="https://learn.microsoft.com/en-us/ai-builder/doc-automation">Document automation toolkit - AI Builder | Microsoft Learn</a>. The inital installation is standard and next-next-finish. You do need some knowledge of Power Platform if you want to get started with this.<br/> The two installations I did stalled on the last step but everything looked in working order after a refresh of the browser.</p> <h2 id="1-setting-up-the-solution">1. Setting Up the Solution</h2> <p>To begin, create a new solution within the Power Platform environment and import all toolkit components. The Toolkit comes as a managed solution, so this way you can make the necesary adjustments to the flow‚Äôs, apps and dataverse tables. This step is straightforward, enabling users to swiftly set up a foundation for their document automation process. <img src="https://github.com/dva81/dva81.github.io/assets/65031840/6f6d19a2-4ba8-48f5-b961-6a53b5bc43bf" alt="image"/></p> <h2 id="2-model-configuration">2. Model Configuration</h2> <p>Next, create a simple model to complete the initial configuration steps within the app. This involves defining the types of documents to be processed and the data fields to be extracted. <img src="https://github.com/dva81/dva81.github.io/assets/65031840/9eb347fd-6b54-44da-833c-067df788d422" alt="image"/></p> <h2 id="3-base-flow-testing">3. Base Flow Testing</h2> <p>Test the base flow by integrating it with an email system. This initial test ensures that the basic document processing pipeline is functioning correctly.</p> <p>Check and test the email importer flow <img src="https://github.com/dva81/dva81.github.io/assets/65031840/70e4aa74-1942-475f-8547-48d6892ab21c" alt="image"/></p> <p>Configure the Power App to use the correct model. <img src="https://github.com/dva81/dva81.github.io/assets/65031840/4d4fd77b-46be-4219-9fa6-5b3ecc7425d4" alt="image"/></p> <p>Ready to go! <img src="https://github.com/dva81/dva81.github.io/assets/65031840/6b63ee00-ae52-4057-967d-47efda211e02" alt="image"/></p> <h2 id="4-integrating-file-imports">4. Integrating File Imports</h2> <p>Adjust the flow to accommodate file imports from SharePoint or Teams. This integration allows for a seamless transition of documents from these storage solutions into the AI Builder processing pipeline. For this I duplicated the email importer flow and adjusted the steps in the flow to retrieve the files from a sharepoint location.</p> <p>It took only a few hours to get the document automation application up and running. After processing a few documents a few opportunities for improvement emerged.</p> <h1 id="customizing-features-for-enhanced-usability">Customizing Features for Enhanced Usability</h1> <h2 id="1-enhancing-the-user-interface">1. Enhancing the User Interface</h2> <p>The out-of-the-box user interface (UI) includes an interactive table, which may not be entirely user-friendly for all scenarios like high volume input or table manipulation. To improve this, custom buttons and actions were created within the app, enhancing the overall user experience (UX) and making the toolkit more intuitive. I added an add, delete and copy row button and a general save button. The copy function is great if lines have similar text in it and were not extracted properly. And the lay-out was tweaked a bit. The pdf viewer was made a bit smaller to allow for more room for the table and fields.</p> <p><img src="https://github.com/dva81/dva81.github.io/assets/65031840/22280ec1-a86a-48e5-9f5a-f66a4463c785" alt="image"/></p> <h2 id="2-overcoming-table-structure-challenges">2. Overcoming Table Structure Challenges</h2> <p>In cases where a complex table structure needs to be extracted over multiple pages, the default capabilities of AI Builder might fall short. To address this, optical character recognition (OCR) and a series of regular expressions were employed. This combination allowed for the extraction of complex data structures from documents, ensuring no information was lost during processing.</p> <h2 id="3-addressing-field-restrictions">3. Addressing Field Restrictions</h2> <p>The default character length restriction in Dataverse tables is set to for example 100 characters. For our model, longer field lengths were necessary. Adjusting these settings in Dataverse was possible but initially caused errors during testing. By tweaking these settings and running multiple tests, the issues were eventually resolved, allowing for smoother data processing.</p> <p><img src="https://github.com/dva81/dva81.github.io/assets/65031840/8d4fa078-950d-4176-a25f-3801a5f67ecd" alt="image"/></p> <h2 id="4-managing-bulk-deletion">4. Managing Bulk Deletion</h2> <p>Bulk deletion of documents is not supported out of the box. To manage this, a manual query was created for document deletion within Dataverse tables. This workaround ensured that unnecessary documents could be efficiently removed without manual intervention.</p> <h1 id="conclusion">Conclusion</h1> <p>Microsoft‚Äôs AI Builder and Document Automation Toolkit offers robust features for automating document processing tasks. While the out-of-the-box functionalities provide a solid starting point, specific customizations and adjustments can significantly enhance usability and performance. By addressing UI challenges, overcoming complex table extraction issues, modifying field restrictions, and implementing manual deletion queries, businesses can tailor the AI Builder to meet their unique requirements, ensuring a more efficient and streamlined document automation process.</p> <p>My focus is on structuring, automating and managing business processes using Agile and DevOps best practices. This creates working environments where business continuity, transparency and human capital come first. Reach out to me on <a href="https://www.linkedin.com/in/dennisvanaelst">LinkedIn</a> or check out my <a href="https://github.com/dva81">github</a> or <a href="https://www.dennisvanaelst.net/">blog</a> for more tips and tricks.</p> <hr/> <p>The ideas and underlying essence are original and generated by a human author. The organization, grammar, and presentation may have been enhanced by the use of AI.</p>]]></content><author><name></name></author><category term="PowerPlatform"/><category term="AI"/><summary type="html"><![CDATA[This blog post delves into the workings of the Document Automation Toolkit within AI Builder, detailing the steps involved in setting it up and the adjustments necessary to tailor it to specific needs.]]></summary></entry><entry><title type="html">A Collection of Must-Reads for the IT consultant</title><link href="https://dva81.github.io/blog/2024/Reading-list/" rel="alternate" type="text/html" title="A Collection of Must-Reads for the IT consultant"/><published>2024-02-29T00:00:00+00:00</published><updated>2024-02-29T00:00:00+00:00</updated><id>https://dva81.github.io/blog/2024/Reading-list</id><content type="html" xml:base="https://dva81.github.io/blog/2024/Reading-list/"><![CDATA[<p>This is my collection of Must-Reads for the IT consultant! Happy Reading</p> <h2 id="the-devops-handbook-how-to-create-world-class-agility-reliability-and-security-in-technology-organizations-by-gene-kim">The DevOPS Handbook How to Create World-Class Agility, Reliability, and Security in Technology Organizations by Gene Kim</h2> <p>https://www.goodreads.com/book/show/26083308-the-devops-handbook</p> <h2 id="the-phoenix-project-by-gene-kim">The Phoenix Project by Gene Kim</h2> <p>https://www.goodreads.com/book/show/17255186-the-phoenix-project</p> <h2 id="pmi-acp-exam-prep-rapid-learning-to-pass-the-pmi-agile-certified-practitioner-pmi-acp-exam">Pmi-acp Exam Prep: Rapid Learning to Pass the Pmi Agile Certified Practitioner Pmi-acp Exam</h2> <p>https://www.goodreads.com/book/show/27276014-pmi-acp-exam-prep</p> <h2 id="the-scrum-guide">The Scrum Guide</h2> <p>https://www.scrum.org/resources/scrum-guide</p> <h2 id="scrum-product-ownership-by-robert-galen">Scrum Product ownership by Robert Galen</h2> <p>https://www.goodreads.com/book/show/44566037-scrum-product-ownership</p> <h2 id="atomic-design">Atomic Design</h2> <p>https://atomicdesign.bradfrost.com</p> <h2 id="flawless-consulting-a-guide-to-getting-your-expertise-used-by-peter-block">Flawless Consulting: A Guide to Getting Your Expertise Used by Peter Block</h2> <p>https://www.goodreads.com/book/show/8265721-flawless-consulting</p> <h2 id="the-7-habits-of-highly-effective-people-powerful-lessons-in-personal-change-by-steven-covey">The 7 Habits of Highly Effective People: Powerful Lessons in Personal Change by Steven Covey</h2> <p>https://www.goodreads.com/book/show/36072.The_7_Habits_of_Highly_Effective_People</p> <h2 id="about-the-archimate-modeling-language">About the ArchiMate Modeling Language</h2> <p>https://www.opengroup.org/archimate-forum/archimate-overview</p> <h2 id="dealing-with-people-you-cant-stand-how-to-bring-out-the-best-in-people-at-their-worst">Dealing with People You Can‚Äôt Stand: How to Bring Out the Best in People at Their Worst</h2> <p>https://www.goodreads.com/book/show/734384.Dealing_with_People_You_Can_t_Stand</p> <p>My focus is on structuring, automating and managing business processes using Agile and DevOps best practices. This creates working environments where business continuity, transparency and human capital come first. Reach out to me on <a href="https://www.linkedin.com/in/dennisvanaelst">LinkedIn</a> or check out my <a href="https://github.com/dva81">github</a> or <a href="https://www.dennisvanaelst.net/">blog</a> for more tips and tricks.</p> <hr/> <p>The ideas and underlying essence are original and generated by a human author. The organization, grammar, and presentation may have been enhanced by the use of AI.</p>]]></content><author><name></name></author><category term="Agile"/><category term="Leadership"/><summary type="html"><![CDATA[This is my collection of Must-Reads for the IT consultant.]]></summary></entry><entry><title type="html">Automating LinkedIn Posts - A Simple Scheduler for Busy Professionals</title><link href="https://dva81.github.io/blog/2024/Automating-LinkedIn-Posts/" rel="alternate" type="text/html" title="Automating LinkedIn Posts - A Simple Scheduler for Busy Professionals"/><published>2024-01-11T00:00:00+00:00</published><updated>2024-01-11T00:00:00+00:00</updated><id>https://dva81.github.io/blog/2024/Automating-LinkedIn-Posts</id><content type="html" xml:base="https://dva81.github.io/blog/2024/Automating-LinkedIn-Posts/"><![CDATA[<p>As a practice lead, staying active on LinkedIn is crucial for promoting both yourself and your business. Many professionals dedicate time to post regularly or leverage scheduling functions to maintain a consistent online presence. However, when it comes to bulk scheduling posts over an extended period, LinkedIn lacks a native feature. Even the LinkedIn API falls short in this aspect, leaving you in need of a customized solution.</p> <p>In my quest to efficiently manage my LinkedIn content, I decided to create a simple scheduler that allows me to plan my posts for the next two years. In this blog post, I‚Äôll walk you through the process of building a Power Automate Flow that meets this requirement.</p> <h1 id="requirements">Requirements</h1> <ul> <li>Dynamic Message Creation: Ensure variation in posts to keep your content engaging.</li> <li>Bi-weekly Scheduling: Automate the process to post every two weeks.</li> <li>Maintain Control: Craft a solution that keeps you in the driver‚Äôs seat.</li> </ul> <h1 id="building-the-power-automate-flow">Building the Power Automate Flow</h1> <p><img src="/assets/img/Automating LinkedIn Posts/Automating LinkedIn Posts (3).png" alt="Automating LinkedIn Posts"/></p> <h2 id="step-1-connect-with-linkedin">Step 1 Connect with LinkedIn</h2> <p>The first step involves creating a connection with LinkedIn using the standard free connector. Simply use your credentials to log in and establish the connection. <img src="/assets/img/Automating LinkedIn Posts/Automating LinkedIn Posts (2).png" alt="Automating LinkedIn Posts"/></p> <h2 id="step-2-dynamic-message-creation">Step 2 Dynamic Message Creation</h2> <p>To add variety to your posts, leverage Power Automate‚Äôs functions. Utilize the rand function to dynamically generate messages, ensuring a mix of content in your posts. <img src="/assets/img/Automating LinkedIn Posts/Automating LinkedIn Posts (5).png" alt="Automating LinkedIn Posts"/></p> <p><img src="/assets/img/Automating LinkedIn Posts/Automating LinkedIn Posts (1).png" alt="Automating LinkedIn Posts"/></p> <h2 id="step-3-bi-weekly-scheduling">Step 3 Bi-weekly Scheduling</h2> <p>Implement a scheduling mechanism within the flow to post every two weeks. This ensures a consistent presence on your LinkedIn profile. <img src="/assets/img/Automating LinkedIn Posts/Automating LinkedIn Posts (4).png" alt="Automating LinkedIn Posts"/></p> <p>Step 4 Stay in Control The entire solution is designed to keep you in control. By dynamically creating messages, scheduling bi-weekly posts, and leveraging Power Automate‚Äôs capabilities, you can confidently manage your LinkedIn content for the next two years.</p> <h1 id="access-the-power-automate-flow">Access the Power Automate Flow</h1> <p>To implement this solution, you can download the source files directly from <a href="https://github.com/dva81/PowerAutomate">GitHub</a>. Don‚Äôt forget to turn the flow on after setting it up.</p> <p>Empower your LinkedIn strategy by taking charge of your posting schedule with this simple yet effective Power Automate Flow. Stay visible, stay engaged, and let automation work for you!</p> <p>My focus is on structuring, automating and managing business processes using Agile and DevOps best practices. This creates working environments where business continuity, transparency and human capital come first. Reach out to me on <a href="https://www.linkedin.com/in/dennisvanaelst">LinkedIn</a> or check out my <a href="https://github.com/dva81">github</a> or <a href="https://www.dennisvanaelst.net/">blog</a> for more tips and tricks.</p> <hr/> <p>The ideas and underlying essence are original and generated by a human author. The organization, grammar, and presentation may have been enhanced by the use of AI.</p>]]></content><author><name></name></author><category term="PowerPlatform"/><summary type="html"><![CDATA[Many professionals dedicate time to post regularly or leverage scheduling functions to maintain a consistent online presence. However, when it comes to bulk scheduling posts, LinkedIn lacks a native feature, leaving you in need of a customized solution.]]></summary></entry><entry><title type="html">Mastering AI Model Validation - A Comprehensive Guide for Success</title><link href="https://dva81.github.io/blog/2024/Model-Validation/" rel="alternate" type="text/html" title="Mastering AI Model Validation - A Comprehensive Guide for Success"/><published>2024-01-02T00:00:00+00:00</published><updated>2024-01-02T00:00:00+00:00</updated><id>https://dva81.github.io/blog/2024/Model-Validation</id><content type="html" xml:base="https://dva81.github.io/blog/2024/Model-Validation/"><![CDATA[<p>AI is everywhere these days! Yet is has existed since the beginning of the computer age. What is so different from 25 years ago? What makes it more powerful, more present? Why all the fuss? Over the last 10 years machine learning has become extremely powerful.</p> <p>Rather than programmers giving machine learning AIs a definitive list of instructions on how to complete a task, the AIs have to learn how to do the task themselves. There are many ways to attempt this, but the most popular approach involves software that is trained by example.</p> <h1 id="the-importance-of-validating-ai-models">The importance of validating AI models</h1> <p>AI is already involved in making important processes (like translations and summarizations) and yet AI is often biased, meaning its recommendations can be too. Time after time, researchers have found that <a href="https://www.newscientist.com/article/2166207-discriminating-algorithms-5-times-ai-showed-prejudice/">neural networks pick up biases from the data sets they are trained on</a>. For example, face recognition algorithms have much lower accuracy for anyone who is not a white man.</p> <p>AI decisions are also opaque or referred to as a ‚ÄúBlack box‚Äù. How neural networks come to conclusions is very hard to analyze, meaning if they make a crucial mistake, such as missing cancer in an image, it‚Äôs very difficult to find out why they made the mistake or to hold them accountable.</p> <blockquote> <p>Validating AI models ensures accuracy, robustness, and reliability.</p> </blockquote> <p>Often creating and validating these sets in a time and resource consuming activity which does not always help the business case due to its labor-intensive nature. But validating AI models is necessary and ensures accuracy, robustness, and reliability.</p> <h1 id="data-splitting-for-model-validation">Data Splitting for Model Validation</h1> <p>The primary reason for data splitting is to avoid <a href="https://en.wikipedia.org/wiki/Overfitting">overfitting</a> , which occurs when the model is too complex and fits the training data too well, resulting in poor generalization performance on new data. <a href="https://machinelearningmastery.com/training-validation-test-split-and-cross-validation-done-right/">By splitting the data, we can ensure that the model is not overfitting to the training data and is generalizing well to new data</a>.</p> <p>Data splitting also provides an unbiased estimate of the model‚Äôs performance. If we use the same data for training and testing, the model will perform well on the training data but may not generalize well to new data. By using a separate testing set, we can obtain an unbiased estimate of the model‚Äôs performance on new data.</p> <h1 id="determining-validation-set-size">Determining Validation Set Size</h1> <p>To calculate the size of the validation set, there is no one-size-fits-all answer. However, a common approach is to use a 70/30 or 80/20 split for the training and validation sets, respectively. The size of the validation set should be large enough to provide a representative sample of the data but small enough to avoid overfitting. A good rule of thumb is to use at least 5% of the total data for the validation set. That means that for a population of 40000 you need a sample set of 2000.</p> <p>This online calculator helps to calculate sample sizes - <a href="https://www.calculator.net/sample-size-calculator.html">Sample Size Calculator</a> - for test and validation purposes. It provides insights into how the right validation set size contributes to an effective model assessment.</p> <p><img src="/assets/img/Model-validation/model-validation4.png" alt="online calculator"/></p> <p>Methods of Model Validation: Cross Validation Cross-validation is a technique used in machine learning to evaluate the performance of a model. It involves dividing the dataset into smaller groups and then averaging the performance in each group to reduce the impact of partition randomness on the results. Nevertheless, each method has its own bias toward more positive or negative results. Here are some of the most commonly used cross-validation techniques:</p> <ol> <li> <p>Train-Test Split Method: This method randomly partitions the dataset into two subsets (called training and test sets) so that the predefined percentage of the entire dataset is in the training set. Then, we train our machine learning model on the training set and evaluate its performance on the test set. In this way, we are always sure that the samples used for training are not used for evaluation and vice versa.</p> </li> <li> <p>K-Fold Cross-Validation: In k-fold cross-validation, we first divide our dataset into k equally sized subsets. Then, we repeat the train-test method k times such that each time one of the k subsets is used as a test set and the rest k-1 subsets are used together as a training set. Finally, we compute the estimate of the model‚Äôs performance estimate by averaging the scores over the k trials.</p> </li> <li> <p>Leave-One-Out Cross-Validation: In leave-one-out cross-validation, we use all but one sample for training and the remaining sample for testing. We repeat this process for all samples in the dataset and average the performance over all trials.</p> </li> </ol> <h1 id="a-power-platform-example">A Power Platform Example</h1> <p>Let us say we have created a model in <a href="https://learn.microsoft.com/en-us/ai-builder/">AI builder</a>, and you want to see if it works as expected. Power Platform comes some standard prediction engines and features, still it is always a good idea to validate the outcome of a process.</p> <p>This technique can also be used with models created by other technologies as well.</p> <p>An easy way to do this in Power platform is with a Power Automate flow.</p> <ol> <li>Put your validation files in one folder. (you can even create them using a generation flow)</li> </ol> <p><img src="/assets/img/Model-validation/model-validation3.png" alt="generation flow"/></p> <ol> <li> <p>Create a database with all the (meta)data you expect the model to find in the files.</p> </li> <li> <p>Create a flow that reads the files, runs the model and verifies the data found against the data source.</p> </li> <li> <p>Put the results in a file or dashboard.</p> </li> </ol> <p>It can look something like this:</p> <p><img src="/assets/img/Model-validation/model-validation2.png" alt="flow"/></p> <h1 id="key-takeaways">Key Takeaways</h1> <p>Data splitting is essential for avoiding overfitting and obtaining an unbiased estimate of the model‚Äôs performance. It is a crucial step in the validation process. The choice of cross-validation technique depends on the size of the dataset, the number of features, and the computational resources available.</p> <p>These techniques are used to evaluate the performance of a machine learning model and to reduce the impact of partition randomness on the results. It helps ensure the overall accuracy, robustness, and reliability of the business process.</p> <p>Check out <a href="https://machinelearningmastery.com/">Machine Learning Mastery</a> where you‚Äôll find ‚Äúnot so dry‚Äù material on this topic.</p> <p>My focus is on structuring, automating and managing business processes using Agile and DevOps best practices. This creates working environments where business continuity, transparency and human capital come first. Reach out to me on <a href="https://www.linkedin.com/in/dennisvanaelst">LinkedIn</a> or check out my <a href="https://github.com/dva81">github</a> or <a href="https://www.dennisvanaelst.net/">blog</a> for more tips and tricks.</p> <hr/> <p>The ideas and underlying essence are original and generated by a human author. The organization, grammar, and presentation may have been enhanced by the use of AI.</p>]]></content><author><name></name></author><category term="PowerPlatform"/><category term="AI"/><summary type="html"><![CDATA[AI is everywhere these days! Yet is has existed since the beginning of the computer age. What is so different from 25 years ago? What makes it more powerful, more present? Why all the fuss? Over the last 10 years machine learning has become extremely powerful.]]></summary></entry><entry><title type="html">Boosting Efficiency Docs-as-Code Strategies with Power Platform and Azure DevOps</title><link href="https://dva81.github.io/blog/2023/Docs-as-Code/" rel="alternate" type="text/html" title="Boosting Efficiency Docs-as-Code Strategies with Power Platform and Azure DevOps"/><published>2023-12-12T00:00:00+00:00</published><updated>2023-12-12T00:00:00+00:00</updated><id>https://dva81.github.io/blog/2023/Docs-as-Code</id><content type="html" xml:base="https://dva81.github.io/blog/2023/Docs-as-Code/"><![CDATA[<p>Some time ago I took over a Power Platform project right after first deploys to production. The application is a collection of over 30 Power Apps and more than 600 other components. With my DevOps background I was really happy to see the Azure DevOps setup the team had put in place to automate the deploy of the hundreds of Power Platform components as much a as possible.</p> <p>If you want to see how that can be done check out this video by Feline Parein. <a href="https://www.youtube.com/watch?v=pv8CyKrL5ds">Feline Parein - How to deploy Power Platform solution company-wide: Azure DevOps can help with CI/CD - YouTube</a></p> <p>As I was new to the project, I had no context to inform my understanding of what was going on or how things were connected. So, I started reading and looking for information. The developers were working on all the new features and releases, so they had little time to address my information needs.</p> <h1 id="why-docs-as-code">Why docs-as-code?</h1> <p>I found a maze of documents, snippets, designs and much more without any solid structure. Everything was there but it was in chaos. After talking to the team, I found out that, like most developers they don‚Äôt like to write documentation, switching tools and work environments, there was no review process, and they did not see the purpose of it as ‚Äúeverything we build is Low-Code‚Äù.</p> <blockquote> <p>My next mission was clear: improve the process, improve the documentation.</p> </blockquote> <p>With docs-as-code, you treat your documentation in the same way as your code. A quick start:</p> <ul> <li> <p>Format: pick a format that is easily versioned and transformed like .md. (Markdown)</p> </li> <li> <p>Versioning: Use a versioning system like GIT just as you would with code or configuration files. No need to append a date or v2.2x at the end.</p> </li> <li> <p>Automation: Transform the docs to any format needed (html, pdf, ‚Ä¶) and distribute them in one go.</p> </li> <li> <p>Validation: Use an approval flow to get the documents approved and signed off.</p> </li> </ul> <h1 id="how-did-we-do-this">How did we do this?</h1> <p>The good thing was the team already tried to put documentation in repositories. We built on those first steps and completed the process.</p> <ul> <li>Create a wiki and publish it as code</li> </ul> <p><img src="/assets/img/Docs-as-code/Docs-as-Code1.png" alt="publish it as code"/></p> <ul> <li>.md as format. Markdown is a lightweight markup language that you can use to add formatting elements to plaintext text documents.</li> </ul> <p><img src="/assets/img/Docs-as-code/Docs-as-Code2.png" alt="publish it as code"/></p> <p><img src="/assets/img/Docs-as-code/Docs-as-Code3.png" alt="publish it as code"/></p> <ul> <li>In the pipeline step the output is generated in pdf format using a standard task in Azure DevOps. and attached to the artifact for deployment.</li> </ul> <p><img src="/assets/img/Docs-as-code/Docs-as-Code4.png" alt="publish it as code"/></p> <ul> <li>Releasing the documentation. In this step we automated the release to the right location for validation. After approval in Azure Devops that version was copied to the end user or production locations in the Power Platform solution.</li> </ul> <p><img src="/assets/img/Docs-as-code/Docs-as-Code6.png" alt="publish it as code"/></p> <p><img src="/assets/img/Docs-as-code/Docs-as-Code5.png" alt="publish it as code"/></p> <h1 id="bringing-it-all-together">Bringing it all together</h1> <blockquote> <p>‚ÄúHappy cows make better milk.‚Äù</p> </blockquote> <p>By improving the overall documentation process, the team is now much more inclined to write documentation and maintain it. Connecting other people to the project is now much easier and we created better continuity for our client as well.</p> <hr/> <p>If you are more interested in the view of a technical writer, you might want to start your journey at http://writethedocs.org.</p> <hr/> <p>My focus is on structuring, automating and managing business processes using Agile and DevOps best practices. This creates team working environments where business continuity, transparency and human capital come first. Reach out to me on LinkedIn or check out my GitHub for more tips and tricks.</p>]]></content><author><name></name></author><category term="DevOps"/><category term="PowerPlatform"/><summary type="html"><![CDATA[Some time ago I took over a Power Platform project right after first deploys to production. The application is a collection of over 30 Power Apps and more than 600 other components. With my DevOps background I was really happy to see the Azure DevOps setup the team had put in place to automate the deploy of the hundreds of Power Platform components as much a as possible.]]></summary></entry></feed>